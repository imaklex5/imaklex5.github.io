<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>NBeats论文笔记 | hyc&#39;s log</title>
<meta name="keywords" content="论文笔记, 时间序列">
<meta name="description" content="NBeats论文笔记 Abstract 我们专注于利用深度学习解决单变量时间序列点预测问题。我们提出了一种深度神经架构，该架构基于后向和前向残差链接以及非常深">
<meta name="author" content="">
<link rel="canonical" href="https://imaklex5.github.io/posts/n-beats-note/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://imaklex5.github.io/favicon/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://imaklex5.github.io/favicon/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://imaklex5.github.io/favicon/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://imaklex5.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://imaklex5.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://imaklex5.github.io/posts/n-beats-note/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "$", right: "$", display: false}
        ]
    });
});
</script>

  

<meta property="og:title" content="NBeats论文笔记" />
<meta property="og:description" content="NBeats论文笔记 Abstract 我们专注于利用深度学习解决单变量时间序列点预测问题。我们提出了一种深度神经架构，该架构基于后向和前向残差链接以及非常深" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://imaklex5.github.io/posts/n-beats-note/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-10-08T14:09:56+08:00" />
<meta property="article:modified_time" content="2024-10-08T14:09:56+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="NBeats论文笔记"/>
<meta name="twitter:description" content="NBeats论文笔记 Abstract 我们专注于利用深度学习解决单变量时间序列点预测问题。我们提出了一种深度神经架构，该架构基于后向和前向残差链接以及非常深"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://imaklex5.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "NBeats论文笔记",
      "item": "https://imaklex5.github.io/posts/n-beats-note/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "NBeats论文笔记",
  "name": "NBeats论文笔记",
  "description": "NBeats论文笔记 Abstract 我们专注于利用深度学习解决单变量时间序列点预测问题。我们提出了一种深度神经架构，该架构基于后向和前向残差链接以及非常深",
  "keywords": [
    "论文笔记", "时间序列"
  ],
  "articleBody": "NBeats论文笔记 Abstract 我们专注于利用深度学习解决单变量时间序列点预测问题。我们提出了一种深度神经架构，该架构基于后向和前向残差链接以及非常深的全连接层栈。该架构具有一系列理想特性：可解释、无需修改即可适用于广泛的目标领域、训练速度快。我们在几个著名的数据集上测试了所提出的架构，包括M3、M4和TOURISM竞赛数据集，其中包含来自不同领域的时间序列。我们展示了N-BEATS的两种配置在所有数据集上的一流性能，其预测准确率比统计基准提高了11%，比去年M4竞赛的冠军提高了3%，M4竞赛是神经网络和统计时间序列模型之间经过领域调整的手工制作的混合模型。我们模型的第一种配置没有采用任何特定于时间序列的组件，它在异构数据集上的表现有力地表明，与公认的观点不同，残差块等深度学习原语本身就足以解决各种预测问题。最后，我们展示了如何对所提出的架构进行扩展，以提供可解释的输出，而不会在准确性方面造成相当大的损失。\nBackground 时序预测方法在金融、工业等方面有着很多的应用，但是与计算机视觉和自然语言处理这样的深度学习技术已经很成熟的领域相比，在时序预测问题上，深度学习、机器学习方法目前仍无法超越传统的统计学方法，目前的SOTA模型依然是DL与统计学方法的混合模型。在这项工作中，作者希望探索纯深度学习方法在时序预测问题上的潜力，并试图通过向模型中添加适当的归纳偏置来使所提出的模型更具可解释性。\nContributions 深度神经架构：这是第一项通过经验证明在M3、M4和TOURISM数据集上不使用时间序列特定组件的纯DL优于成熟统计方法的工作，这为在 TS 预测中使用纯 ML 提供了长期缺失的概念证明，并增强了继续推进该领域研究的动力。 时间序列的可解释DL：除了准确性方面的优势，该文章的工作还了表明设计一种具有可解释输出的架构是可行的，可以用与传统分解技术（如 “季节性-趋势性\"方法）相同的方式来使用这种架构。 Approach 本文所提出的模型结构如上图所示，主要由基本块（左）堆叠而成，基本块堆叠得到一个栈，其输出由所有块的输出相加得到；多个栈串联得到完整的模型，最终输出为所有栈输出之和。模型训练输入采用长度为$nH$的滑动窗口，输出为长度为$H$的预测序列。\nBasic Block 本文设计了简单且通用的基本块结构。第一个块的输入为原始的输入序列$x_{0}$，而后续的块的输入均为前一个块的残差$x_{l-1} - \\hat{x}{l-1}$（$x{l}$表示第$l$个块，$\\hat{x_{{l}}}$表示第$l$个块的输出）。块内分为两个部分，输入的序列首先会经过一个全连接网络，该部分会产生拓展系数的后向预测器$\\theta^b$和前向预测器$\\theta^f$。所得的预测器接下来会分别进入到各自的基函数层$g^f$和$g^b$，这一部分会从训练数据中学习到各自的一组基函数，然后将拓展系数投影到不同的空间中得到最终的输出$\\hat{x}$和$\\hat{y}$。 $$ \\begin{array} h_{1} = FC(x_{l}), \\quad h_{2} = FC(h_{1}), \\quad h_{3} = FC(h_{2}), \\quad h_{4} = FC({h_{3}}) \\ \\theta^f = \\mathop{Linear}^f(h_{4}), \\theta^b=\\mathop{Linear}^b(h_{4}) \\ \\hat{x_{l}} = g^b(\\theta^b), \\quad \\hat{y_{l}} = g^f(\\theta^f) \\end{array} $$ 这里的$FC$是标准的全连接层，其中采用了$\\mathrm{ReLU}$激活函数。 该模块的设计目标如下：\n预测前向拓展系数$\\theta^f$，通过对$g^f$所提供的基向量加权来预测部分序列$\\hat{y}$ 预测后向拓展系数$\\theta^b$，通过对$g^b$所提供的基向量加权来生成对输入$x$的估计值$\\hat{x}$，以达到序列分解的目的，帮助下游块进行学习。 Doubly Residual Stacking 本文还设计了双残差堆叠的结构（中）。除了模型中的第一个块，下游的块所接收的输入全都是前一区块的残差；一个栈的最终结果由其中所有块的预测输出相加所得，表示如下： $$ x_{l} = x_{l-1} - \\hat{x}{l-1}, \\quad y = \\sum{i=0}^{l} \\hat{y}{i} $$ 可以后向传播的过程看做是对序列的层次分解过程。前一个区块会学习如何近似输入的信息，得到h后向输出$\\hat{x}{l-1}$，因此$x_{l-1} - \\hat{x}_{l-1}$所表示的就是当前块没有很好地拟合的部分，下游模块继续处理这些残差序列可以大大简化其预测任务。每一个块都会生成一个局部的预测结果，这些结果先是聚合为栈的结果，然后聚合为最终的输出结果，时序数据在这个过程中被从上至下地分层分解。\nInterpretability 本文提出了两种架构，分别是通用的纯DL架构和引入了时序先验信息的可解释模型。\nGenetic Architecture 在通用架构下，$g^f$和$g^b$仅仅是用于将FC层的输出进行投影的线性层，第$l$个块的输出可以表示如下： $$ \\hat{x}{l} = V{l}^b\\theta_{l}^b + b_{l}^b, \\quad \\hat{y}=V_{l}^f\\theta_{l}^f + b_{l}^f $$ FC层的输出基于线性层所学习到的一组基向量来预测分解后的部分序列，矩阵$V_{l}^f$的形状为$H \\times \\mathop{dim}(\\theta_{l}^f)$，其中$H$代表预测域中的每一个离散时间点，$\\mathop{dim}(\\theta^f)$为基向量的索引，每一列是线性层所学习到的基向量，这些基向量都可以看作是时域下的波形，拓展系数将这些波形进行线性组合，得到预测的波形。由于没有对$V_{l}^f$施加任何的约束，这些波形完全是由网络自助学习到的，没有特定的形式，因此不具备可解释性\nInterpretable Architecture 可解释性架构基于上述的通用架构，在其基础之上为基函数层引入了支持时间序列分解的先验信息。\n趋势性：时间序列中的趋势性具有单调、波动小的特点，本论文将基函数层$g^f,g^b$约束为一个低阶（高阶多项式容易过拟合）的多项式函数来模拟这种特点 $$ \\hat{y} = \\sum_{i=0}^p\\theta^f $$ 季节性：时间序列的季节性呈现出有规律的周期性波动的特点，本文使用傅里叶级数作为基函数来建模这种特点 $$ \\hat{y}{s} = \\sum{i=0}^{\\lfloor H / 2 - 1 \\rfloor } \\theta_{s}^f\\cos(2\\pi it) + \\theta_{s}^f\\sin(2\\pi it) $$ 可解释性架构由两个栈组成：趋势性栈和季节性栈。基于前述的双残差堆叠方法，在经过第一个栈的时候，时间序列中的趋势性信息会被移除，使得两个栈可以专注处理自己的部分，并且趋势性和季节性的预测可以作为单独的输出，最终预测结果由两部分叠加得到。 Result 指标对比 可视化预测结果：-G代表通用模型，-I代表可解释性模型 Summary NBeats是较早采用全MLP结构进行时间序列建模的模型，在网络中采用了MLP网络、残差拟合和basis建模的方法。模型包括多个stack，每个stack包含多个block，block是该网络的基本单元，每个block由多个全连接层构成，时间序列输入在一个block中首先被映射为expansion coeffecients，然后在通过basis映射回时间序列，最终输出一个预测的序列，通过为basis引入时序先验信息还可以实现模型的可解释性。每个块接受的输入都是上一层block的输入减去输出，以使每一层需要处理的都是上一侧无法正确拟合的残差，最终达到时间序列逐层分解的效果，每一层都会预测时间序列的一部分，最终的结果由各层输出叠加得到。\n",
  "wordCount" : "2731",
  "inLanguage": "en",
  "datePublished": "2024-10-08T14:09:56+08:00",
  "dateModified": "2024-10-08T14:09:56+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://imaklex5.github.io/posts/n-beats-note/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "hyc's log",
    "logo": {
      "@type": "ImageObject",
      "url": "https://imaklex5.github.io/favicon/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://imaklex5.github.io/" accesskey="h" title="hyc&#39;s log (Alt + H)">hyc&#39;s log</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://imaklex5.github.io/" title="🏠️主页">
                    <span>🏠️主页</span>
                </a>
            </li>
            <li>
                <a href="https://imaklex5.github.io/archives/" title="⌛️时间线">
                    <span>⌛️时间线</span>
                </a>
            </li>
            <li>
                <a href="https://imaklex5.github.io/categories/" title="📑分类">
                    <span>📑分类</span>
                </a>
            </li>
            <li>
                <a href="https://imaklex5.github.io/tags/" title="🏷️标签">
                    <span>🏷️标签</span>
                </a>
            </li>
            <li>
                <a href="https://imaklex5.github.io/search/" title="🔎搜索">
                    <span>🔎搜索</span>
                </a>
            </li>
            <li>
                <a href="https://imaklex5.github.io/links/" title="🤝友链">
                    <span>🤝友链</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      NBeats论文笔记
    </h1>
    <div class="post-meta"><span title='2024-10-08 14:09:56 +0800 +0800'>October 8, 2024</span>&nbsp;·&nbsp;6 min

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#nbeats%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0" aria-label="NBeats论文笔记">NBeats论文笔记</a><ul>
                        
                <li>
                    <a href="#abstract" aria-label="Abstract">Abstract</a></li>
                <li>
                    <a href="#background" aria-label="Background">Background</a></li>
                <li>
                    <a href="#contributions" aria-label="Contributions">Contributions</a></li>
                <li>
                    <a href="#approach" aria-label="Approach">Approach</a><ul>
                        
                <li>
                    <a href="#basic-block" aria-label="Basic Block">Basic Block</a></li>
                <li>
                    <a href="#doubly-residual-stacking" aria-label="Doubly Residual Stacking">Doubly Residual Stacking</a></li>
                <li>
                    <a href="#interpretability" aria-label="Interpretability">Interpretability</a><ul>
                        
                <li>
                    <a href="#genetic-architecture" aria-label="Genetic Architecture">Genetic Architecture</a></li>
                <li>
                    <a href="#interpretable-architecture" aria-label="Interpretable Architecture">Interpretable Architecture</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#result" aria-label="Result">Result</a></li>
                <li>
                    <a href="#summary" aria-label="Summary">Summary</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="nbeats论文笔记">NBeats论文笔记<a hidden class="anchor" aria-hidden="true" href="#nbeats论文笔记">#</a></h1>
<h2 id="abstract">Abstract<a hidden class="anchor" aria-hidden="true" href="#abstract">#</a></h2>
<p>我们专注于利用深度学习解决<strong>单变量时间序列点预测</strong>问题。我们提出了一种深度神经架构，该架构基于<strong>后向和前向残差链接</strong>以及非常深的<strong>全连接层栈</strong>。该架构具有一系列理想特性：<strong>可解释</strong>、无需修改即可适用于广泛的目标领域、训练速度快。我们在几个著名的数据集上测试了所提出的架构，包括M3、M4和TOURISM竞赛数据集，其中包含来自不同领域的时间序列。我们展示了N-BEATS的两种配置在所有数据集上的一流性能，其预测准确率比统计基准提高了11%，比去年M4竞赛的冠军提高了3%，M4竞赛是神经网络和统计时间序列模型之间经过领域调整的手工制作的混合模型。我们模型的第一种配置没有采用任何特定于时间序列的组件，它在异构数据集上的表现有力地表明，与公认的观点不同，<strong>残差块等深度学习原语本身就足以解决各种预测问题</strong>。最后，我们展示了如何对所提出的架构进行扩展，以提供可解释的输出，而不会在准确性方面造成相当大的损失。</p>
<h2 id="background">Background<a hidden class="anchor" aria-hidden="true" href="#background">#</a></h2>
<p>时序预测方法在金融、工业等方面有着很多的应用，但是与计算机视觉和自然语言处理这样的深度学习技术已经很成熟的领域相比，在时序预测问题上，深度学习、机器学习方法目前仍无法超越传统的统计学方法，目前的SOTA模型依然是DL与统计学方法的混合模型。在这项工作中，作者希望探索纯深度学习方法在时序预测问题上的潜力，并试图通过向模型中添加适当的归纳偏置来使所提出的模型更具可解释性。</p>
<h2 id="contributions">Contributions<a hidden class="anchor" aria-hidden="true" href="#contributions">#</a></h2>
<ol>
<li>深度神经架构：这是第一项通过经验证明在M3、M4和TOURISM数据集上不使用时间序列特定组件的<strong>纯DL</strong>优于成熟统计方法的工作，这为在 TS 预测中使用纯 ML 提供了长期缺失的概念证明，并增强了继续推进该领域研究的动力。</li>
<li>时间序列的可解释DL：除了准确性方面的优势，该文章的工作还了表明设计一种具有可解释输出的架构是可行的，可以用与传统分解技术（如 &ldquo;季节性-趋势性&quot;方法）相同的方式来使用这种架构。</li>
</ol>
<h2 id="approach">Approach<a hidden class="anchor" aria-hidden="true" href="#approach">#</a></h2>
<p><img loading="lazy" src="https://drv.imaklex.com/d/1drv/imgs/20240923225121.png" alt="模型架构"  />

本文所提出的模型结构如上图所示，主要由基本块（左）堆叠而成，基本块堆叠得到一个栈，其输出由所有块的输出相加得到；多个栈串联得到完整的模型，最终输出为所有栈输出之和。模型训练输入采用长度为$nH$的滑动窗口，输出为长度为$H$的预测序列。</p>
<h3 id="basic-block">Basic Block<a hidden class="anchor" aria-hidden="true" href="#basic-block">#</a></h3>
<p>本文设计了简单且通用的基本块结构。第一个块的输入为原始的输入序列$x_{0}$，而后续的块的输入均为前一个块的残差$x_{l-1} - \hat{x}<em>{l-1}$（$x</em>{l}$表示第$l$个块，$\hat{x_{{l}}}$表示第$l$个块的输出）。块内分为两个部分，输入的序列首先会经过一个全连接网络，该部分会产生拓展系数的后向预测器$\theta^b$和前向预测器$\theta^f$。所得的预测器接下来会分别进入到各自的基函数层$g^f$和$g^b$，这一部分会从训练数据中学习到各自的一组基函数，然后将拓展系数投影到不同的空间中得到最终的输出$\hat{x}$和$\hat{y}$。
$$
\begin{array}
h_{1} = FC(x_{l}), \quad h_{2} = FC(h_{1}), \quad h_{3} = FC(h_{2}), \quad h_{4}  = FC({h_{3}}) \
\theta^f = \mathop{Linear}^f(h_{4}), \theta^b=\mathop{Linear}^b(h_{4}) \
\hat{x_{l}} = g^b(\theta^b), \quad \hat{y_{l}} = g^f(\theta^f)
\end{array}
$$
这里的$FC$是标准的全连接层，其中采用了$\mathrm{ReLU}$激活函数。
该模块的设计目标如下：</p>
<ol>
<li>预测前向拓展系数$\theta^f$，通过对$g^f$所提供的基向量加权来预测部分序列$\hat{y}$</li>
<li>预测后向拓展系数$\theta^b$，通过对$g^b$所提供的基向量加权来生成对输入$x$的估计值$\hat{x}$，以达到序列分解的目的，帮助下游块进行学习。</li>
</ol>
<h3 id="doubly-residual-stacking">Doubly Residual Stacking<a hidden class="anchor" aria-hidden="true" href="#doubly-residual-stacking">#</a></h3>
<p>本文还设计了双残差堆叠的结构（中）。除了模型中的第一个块，下游的块所接收的输入全都是前一区块的残差；一个栈的最终结果由其中所有块的预测输出相加所得，表示如下：
$$
x_{l} = x_{l-1} - \hat{x}<em>{l-1}, \quad y = \sum</em>{i=0}^{l} \hat{y}<em>{i}
$$
可以后向传播的过程看做是对序列的层次分解过程。前一个区块会学习如何近似输入的信息，得到h后向输出$\hat{x}</em>{l-1}$，因此$x_{l-1} - \hat{x}_{l-1}$所表示的就是当前块没有很好地拟合的部分，下游模块继续处理这些残差序列可以大大简化其预测任务。每一个块都会生成一个局部的预测结果，这些结果先是聚合为栈的结果，然后聚合为最终的输出结果，时序数据在这个过程中被从上至下地分层分解。</p>
<h3 id="interpretability">Interpretability<a hidden class="anchor" aria-hidden="true" href="#interpretability">#</a></h3>
<p>本文提出了两种架构，分别是通用的纯DL架构和引入了时序先验信息的可解释模型。</p>
<h4 id="genetic-architecture">Genetic Architecture<a hidden class="anchor" aria-hidden="true" href="#genetic-architecture">#</a></h4>
<p>在通用架构下，$g^f$和$g^b$仅仅是用于将FC层的输出进行投影的线性层，第$l$个块的输出可以表示如下：
$$
\hat{x}<em>{l} = V</em>{l}^b\theta_{l}^b + b_{l}^b, \quad \hat{y}=V_{l}^f\theta_{l}^f + b_{l}^f
$$
FC层的输出基于线性层所学习到的一组基向量来预测分解后的部分序列，矩阵$V_{l}^f$的形状为$H \times \mathop{dim}(\theta_{l}^f)$，其中$H$代表预测域中的每一个离散时间点，$\mathop{dim}(\theta^f)$为基向量的索引，每一列是线性层所学习到的基向量，这些基向量都可以看作是时域下的波形，拓展系数将这些波形进行线性组合，得到预测的波形。由于没有对$V_{l}^f$施加任何的约束，这些波形完全是由网络自助学习到的，没有特定的形式，因此不具备可解释性</p>
<h4 id="interpretable-architecture">Interpretable Architecture<a hidden class="anchor" aria-hidden="true" href="#interpretable-architecture">#</a></h4>
<p>可解释性架构基于上述的通用架构，在其基础之上为基函数层引入了支持时间序列分解的先验信息。</p>
<ol>
<li>趋势性：时间序列中的趋势性具有单调、波动小的特点，本论文将基函数层$g^f,g^b$约束为一个低阶（高阶多项式容易过拟合）的多项式函数来模拟这种特点
$$
\hat{y} = \sum_{i=0}^p\theta^f
$$</li>
<li>季节性：时间序列的季节性呈现出有规律的周期性波动的特点，本文使用傅里叶级数作为基函数来建模这种特点
$$
\hat{y}<em>{s} = \sum</em>{i=0}^{\lfloor H / 2 - 1 \rfloor } \theta_{s}^f\cos(2\pi it) + \theta_{s}^f\sin(2\pi it)
$$
可解释性架构由两个栈组成：趋势性栈和季节性栈。基于前述的双残差堆叠方法，在经过第一个栈的时候，时间序列中的趋势性信息会被移除，使得两个栈可以专注处理自己的部分，并且趋势性和季节性的预测可以作为单独的输出，最终预测结果由两部分叠加得到。</li>
</ol>
<h2 id="result">Result<a hidden class="anchor" aria-hidden="true" href="#result">#</a></h2>
<p>指标对比
<img loading="lazy" src="https://drv.imaklex.com/d/1drv/imgs/56712a6c57da2d909cbb24bebfe512dd1b8a69b2.png" alt="指标结果"  />

可视化预测结果：-G代表通用模型，-I代表可解释性模型
<img loading="lazy" src="https://drv.imaklex.com/d/1drv/imgs/75893a57c246c857c1be7c89fb7735f72c810f02.png" alt="预测结果"  />
</p>
<h2 id="summary">Summary<a hidden class="anchor" aria-hidden="true" href="#summary">#</a></h2>
<p>NBeats是较早采用<strong>全MLP结构</strong>进行时间序列建模的模型，在网络中采用了MLP网络、残差拟合和basis建模的方法。模型包括多个stack，每个stack包含多个block，block是该网络的基本单元，每个block由多个全连接层构成，时间序列输入在一个block中首先被映射为expansion coeffecients，然后在通过basis映射回时间序列，最终输出一个预测的序列，通过为basis引入时序先验信息还可以实现模型的可解释性。每个块接受的输入都是上一层block的输入减去输出，以使每一层需要处理的都是上一侧无法正确拟合的残差，最终达到时间序列逐层分解的效果，每一层都会预测时间序列的一部分，最终的结果由各层输出叠加得到。</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://imaklex5.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></li>
      <li><a href="https://imaklex5.github.io/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/">时间序列</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://imaklex5.github.io/">hyc&#39;s log</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
